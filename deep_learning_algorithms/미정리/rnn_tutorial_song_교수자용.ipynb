{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음악 생성 인공지능 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data:  '나비야' 노래를 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 필요 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 연산 라이브러리 numpy 호출\n",
    "import numpy as np\n",
    "# 딥러닝 프레임워크 torch 호출\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 노래 데이터(시계열 데이터)를 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 소리 데이터를 활용하기 위해서는 음계-박자 페어를 컴퓨터가 이해 가능한 숫자로 바꿀 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 사전 정의\n",
    "code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n",
    "            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n",
    "\n",
    "idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n",
    "            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 데이터 정의 - '나비야'\n",
    "\n",
    "seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n",
    "       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n",
    "       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n",
    "       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성 함수        \n",
    "def seq2dataset(seq, window_size):\n",
    "    dataset = []\n",
    "    for i in range(len(seq)-window_size):\n",
    "        subset = seq[i:(i+window_size+1)]\n",
    "        dataset.append([code2idx[item] for item in subset])\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성하기\n",
    "WINDOW_SIZE = 4\n",
    "dataset = seq2dataset(seq, window_size = WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력(X)과 출력(Y) 변수로 분리하기\n",
    "X_train = dataset[:,0:4]\n",
    "y_train = dataset[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코드의 종류 갯수\n",
    "max_idx_value = 13\n",
    "\n",
    "# 입력값 정규화 시키기\n",
    "X_train = X_train / float(max_idx_value)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_train = X_train.view(-1,1,WINDOW_SIZE)\n",
    "\n",
    "# 라벨값에 대한 one-hot 인코딩 수행\n",
    "y_train = torch.from_numpy(y_train).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training shape:', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 및 DataLoader 정의\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, rnn_h_size, fnn_h_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # RNN 함수 정의\n",
    "        #self.rnn = nn.RNN(input_size= input_size, hidden_size=rnn_h_size, num_layers=1, batch_first=True)\n",
    "        self.rnn = nn.LSTM(input_size= input_size, hidden_size=rnn_h_size, num_layers=1, batch_first=True)\n",
    "        #self.rnn = nn.GRU(input_size= input_size, hidden_size=rnn_h_size, num_layers=1, batch_first=True)\n",
    "\n",
    "        # fully-connected layer 함수 정의\n",
    "        self.fc1 = nn.Linear(rnn_h_size, fnn_h_size)\n",
    "        self.fc2 = nn.Linear(fnn_h_size, 14)\n",
    "\n",
    "        # nonlinearity - ReLU 함수 정의\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # RNN layer \n",
    "        x, _ = self.rnn(x)\n",
    "        #x, (hidden, c) = self.rnn(x)\n",
    "\n",
    "        # fully-connected layers\n",
    "        x = self.fc1(x[:,-1])\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[-1]\n",
    "rnn_h_size = input_size\n",
    "fnn_h_size = 32\n",
    "\n",
    "net = Net(input_size = input_size, rnn_h_size = rnn_h_size, fnn_h_size = fnn_h_size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define a Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter 설정\n",
    "\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function 및 optimizer 설정\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 epoch을 반복하며 RNN 모델 학습\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        pred_list = []\n",
    "        labels_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in train_loader:\n",
    "                sequences, labels = data\n",
    "                \n",
    "                # 예측값 출력\n",
    "                pred = net(sequences)\n",
    "                pred_list.append(pred)\n",
    "                labels_list.append(labels)\n",
    "\n",
    "        pred_list = torch.vstack(pred_list)\n",
    "        labels_list = torch.hstack(labels_list)\n",
    "        \n",
    "        train_acc = accuracy_score(pred_list.argmax(1).numpy(), labels_list)\n",
    "\n",
    "\n",
    "        print('epoch: %d, loss: %.3f, train_acc: %.3f'%((epoch+1), loss.item(), train_acc))\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 저장하기\n",
    "\n",
    "PATH = './butterfly.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델의 Parameter 불러오기\n",
    "\n",
    "net = Net(input_size = X_train.shape[-1], rnn_h_size = rnn_h_size, fnn_h_size = fnn_h_size)\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Network on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_count = 50 # 최대 예측 개수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 스텝 예측\n",
    "seq_out = ['g8', 'e8', 'e4', 'f8']\n",
    "pred_list = []\n",
    "labels_list = []\n",
    "# 모델 학습을 종료하였으므로 gradient 계산을 할 필요가 없음\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        sequences, labels = data\n",
    "        \n",
    "        # 예측값 출력\n",
    "        pred = net(sequences)\n",
    "        pred_list.append(pred)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "pred_list = torch.vstack(pred_list)\n",
    "labels_list = torch.hstack(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pred_count):\n",
    "    idx = pred_list[i].argmax().item() # one-hot 인코딩을 인덱스 값으로 변환\n",
    "    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n",
    "    \n",
    "print(\"one step prediction : \", seq_out)\n",
    "\n",
    "one_step_acc = accuracy_score(pred_list.argmax(1).numpy(), labels_list)\n",
    "print('accuracy:',one_step_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 곡 전체 예측\n",
    "seq_in = ['g8', 'e8', 'e4', 'f8']\n",
    "seq_out = seq_in\n",
    "seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "\n",
    "for i in range(pred_count):\n",
    "    sample_in = torch.tensor(seq_in).view(1,1,4)\n",
    "    pred_out = net(sample_in)\n",
    "    pred_list.append(pred_out)\n",
    "    \n",
    "    idx = pred_out.argmax(1).item()\n",
    "    seq_out.append(idx2code[idx])\n",
    "    seq_in.append(idx / float(max_idx_value))\n",
    "    seq_in.pop(0)\n",
    "\n",
    "print(\"full song prediction : \", seq_out)\n",
    "\n",
    "pred_list = torch.vstack(pred_list)\n",
    "one_step_acc = accuracy_score(pred_list.argmax(1).numpy(), labels_list)\n",
    "print('accuracy:',one_step_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "38349969c5a35fc145d3eb76abcd52d109b3752c06b8be4f70b701e6a0425b3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
